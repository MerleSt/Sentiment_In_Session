{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel\n",
    "import pandas as pd\n",
    "import os\n",
    "# Set TOKENIZERS_PARALLELISM to false before importing the tokenizers\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:46:02.207006Z",
     "start_time": "2023-11-15T11:45:58.185616Z"
    }
   },
   "id": "d36693109496cfa9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = SentimentModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:46:03.776478Z",
     "start_time": "2023-11-15T11:46:02.207916Z"
    }
   },
   "id": "49d14ca4c1dc2936"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/combined_df.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:47:01.637643Z",
     "start_time": "2023-11-15T11:46:53.677528Z"
    }
   },
   "id": "28ea2486bd2a7497"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   Election_Period  Session        Date            Start         End_Time  \\\n0               15        1  2002-10-17  0 days 11:00:00  0 days 15:40:00   \n1               15        1  2002-10-17  0 days 11:00:00  0 days 15:40:00   \n2               15        1  2002-10-17  0 days 11:00:00  0 days 15:40:00   \n3               15        1  2002-10-17  0 days 11:00:00  0 days 15:40:00   \n4               15        1  2002-10-17  0 days 11:00:00  0 days 15:40:00   \n\n                       Speaker  \\\n0  Alterspräsident Otto Schily   \n1  Alterspräsident Otto Schily   \n2  Alterspräsident Otto Schily   \n3  Alterspräsident Otto Schily   \n4  Alterspräsident Otto Schily   \n\n                                         Text_Spoken  \\\n0  Meine sehr verehrten Damen und sehr geehrten H...   \n1  Von Paul Löbeüber Konrad Adenauerbis hin zu al...   \n2  Nur Willy Brandtwar 1983 acht Monate jünger, a...   \n3  Das Amt des Alterspräsiden ten blieb Willy Bra...   \n4  Den Hinweis daraufsollten Sie, was meine Leben...   \n\n                                           Reactions         Name Party  \\\n0                                                NaN  Otto Schily   SPD   \n1                                                NaN  Otto Schily   SPD   \n2                                                NaN  Otto Schily   SPD   \n3                                                NaN  Otto Schily   SPD   \n4  Heiterkeit bei der SPD und dem BÜND NIS 90/DIE...  Otto Schily   SPD   \n\n        Position  \n0  Abgeordnete*r  \n1  Abgeordnete*r  \n2  Abgeordnete*r  \n3  Abgeordnete*r  \n4  Abgeordnete*r  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Election_Period</th>\n      <th>Session</th>\n      <th>Date</th>\n      <th>Start</th>\n      <th>End_Time</th>\n      <th>Speaker</th>\n      <th>Text_Spoken</th>\n      <th>Reactions</th>\n      <th>Name</th>\n      <th>Party</th>\n      <th>Position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2002-10-17</td>\n      <td>0 days 11:00:00</td>\n      <td>0 days 15:40:00</td>\n      <td>Alterspräsident Otto Schily</td>\n      <td>Meine sehr verehrten Damen und sehr geehrten H...</td>\n      <td>NaN</td>\n      <td>Otto Schily</td>\n      <td>SPD</td>\n      <td>Abgeordnete*r</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2002-10-17</td>\n      <td>0 days 11:00:00</td>\n      <td>0 days 15:40:00</td>\n      <td>Alterspräsident Otto Schily</td>\n      <td>Von Paul Löbeüber Konrad Adenauerbis hin zu al...</td>\n      <td>NaN</td>\n      <td>Otto Schily</td>\n      <td>SPD</td>\n      <td>Abgeordnete*r</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2002-10-17</td>\n      <td>0 days 11:00:00</td>\n      <td>0 days 15:40:00</td>\n      <td>Alterspräsident Otto Schily</td>\n      <td>Nur Willy Brandtwar 1983 acht Monate jünger, a...</td>\n      <td>NaN</td>\n      <td>Otto Schily</td>\n      <td>SPD</td>\n      <td>Abgeordnete*r</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2002-10-17</td>\n      <td>0 days 11:00:00</td>\n      <td>0 days 15:40:00</td>\n      <td>Alterspräsident Otto Schily</td>\n      <td>Das Amt des Alterspräsiden ten blieb Willy Bra...</td>\n      <td>NaN</td>\n      <td>Otto Schily</td>\n      <td>SPD</td>\n      <td>Abgeordnete*r</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2002-10-17</td>\n      <td>0 days 11:00:00</td>\n      <td>0 days 15:40:00</td>\n      <td>Alterspräsident Otto Schily</td>\n      <td>Den Hinweis daraufsollten Sie, was meine Leben...</td>\n      <td>Heiterkeit bei der SPD und dem BÜND NIS 90/DIE...</td>\n      <td>Otto Schily</td>\n      <td>SPD</td>\n      <td>Abgeordnete*r</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:47:01.643262Z",
     "start_time": "2023-11-15T11:47:01.640880Z"
    }
   },
   "id": "6af4c7bc0ff6d2ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46dfc21724f838c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Reset the index of the dataframe\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:36.235558Z",
     "start_time": "2023-11-11T10:44:35.887236Z"
    }
   },
   "id": "6a617e8835e4cf09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline and function to process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1fc8ead888492d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.608643Z",
     "start_time": "2023-11-11T10:44:36.604529Z"
    }
   },
   "id": "fca1c323e6108958"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('lxyuan/distilbert-base-multilingual-cased-sentiments-student')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.762566Z",
     "start_time": "2023-11-11T10:44:38.609408Z"
    }
   },
   "id": "7a5f266abb2c281a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# This is the final one I can use!\n",
    "# Assuming sentiment_pipeline is a predefined function that outputs the sentiment analysis in the list of dictionaries format\n",
    "\n",
    "def split_into_chunks(text, chunk_size=512):\n",
    "    # Split text into chunks of max_length only if it's longer than max_length\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)] if len(text) > chunk_size else [text]\n",
    "\n",
    "def get_sentiment(text, sentiment_pipeline):\n",
    "    # Split the text into chunks if necessary and get sentiment for each chunk\n",
    "    chunks = split_into_chunks(text)\n",
    "    chunk_sentiments = [sentiment_pipeline(chunk) for chunk in chunks]\n",
    "    return chunk_sentiments, chunks\n",
    "\n",
    "def unpack_sentiments(sentiment_data):\n",
    "    chunk_sentiments, chunks = sentiment_data\n",
    "    # Calculate the total length of the text to determine the weights\n",
    "    total_length = sum(len(chunk) for chunk in chunks)\n",
    "    # Initialize a dictionary with default scores\n",
    "    weighted_scores = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    # Calculate weighted scores\n",
    "    for sentiments, chunk in zip(chunk_sentiments, chunks):\n",
    "        chunk_weight = len(chunk) / total_length\n",
    "        for sentiment in sentiments[0]:\n",
    "            label = sentiment['label'].lower()  # Convert label to lowercase to match the keys in scores\n",
    "            # Add the weighted score\n",
    "            weighted_scores[label] += sentiment['score'] * chunk_weight\n",
    "    return pd.Series(weighted_scores)\n",
    "\n",
    "def weighted_sentiment_analysis_3(df, sentiment_pipeline):\n",
    "    # Apply the sentiment pipeline to the 'Text_Spoken' column, splitting into chunks if necessary\n",
    "    df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n",
    "\n",
    "    # Split the sentiment scores into separate columns with weighted averaging\n",
    "    sentiments_df = df['Sentiment_Data'].apply(unpack_sentiments)\n",
    "    df = df.join(sentiments_df)\n",
    "\n",
    "    # Drop the 'Sentiment_Data' column as it's no longer needed\n",
    "    df.drop(columns=['Sentiment_Data'], inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.768585Z",
     "start_time": "2023-11-11T10:44:38.764707Z"
    }
   },
   "id": "54d16d35dba9a3e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use chunks of 100 000 sentences and combine them later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a163c213224e3205"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started chunk: 3500000\n",
      "Starting Time = 22:39:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3500000\n",
      "Successfully finished chunk: 3500000\n",
      "Ending Time = 01:22:12\n",
      "Started chunk: 3600000\n",
      "Starting Time = 01:22:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3600000\n",
      "Successfully finished chunk: 3600000\n",
      "Ending Time = 04:41:09\n",
      "Started chunk: 3700000\n",
      "Starting Time = 04:41:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3700000\n",
      "Successfully finished chunk: 3700000\n",
      "Ending Time = 08:01:37\n",
      "Started chunk: 3800000\n",
      "Starting Time = 08:01:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3800000\n",
      "Successfully finished chunk: 3800000\n",
      "Ending Time = 08:59:59\n",
      "Started chunk: 3900000\n",
      "Starting Time = 08:59:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3900000\n",
      "Successfully finished chunk: 3900000\n",
      "Ending Time = 09:30:16\n",
      "Started chunk: 4000000\n",
      "Starting Time = 09:30:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4000000\n",
      "Successfully finished chunk: 4000000\n",
      "Ending Time = 10:00:47\n",
      "Started chunk: 4100000\n",
      "Starting Time = 10:00:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4100000\n",
      "Successfully finished chunk: 4100000\n",
      "Ending Time = 10:31:50\n",
      "Started chunk: 4200000\n",
      "Starting Time = 10:31:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4200000\n",
      "Successfully finished chunk: 4200000\n",
      "Ending Time = 11:02:38\n",
      "Started chunk: 4300000\n",
      "Starting Time = 11:02:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4300000\n",
      "Successfully finished chunk: 4300000\n",
      "Ending Time = 11:34:15\n",
      "Started chunk: 4400000\n",
      "Starting Time = 11:34:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4400000\n",
      "Successfully finished chunk: 4400000\n",
      "Ending Time = 12:06:03\n",
      "Started chunk: 4500000\n",
      "Starting Time = 12:06:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4500000\n",
      "Successfully finished chunk: 4500000\n",
      "Ending Time = 12:15:27\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into chunks of 100000 lines\n",
    "for i in range(3500000, len(df), 100000):\n",
    "    print(f'Started chunk: {i}')\n",
    "    now = datetime.now()\n",
    "    starting_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Starting Time =\", starting_time)\n",
    "    chunk = df[i:i+100000]\n",
    "    chunk = weighted_sentiment_analysis_3(chunk, sentiment_pipeline)\n",
    "    print(f'Writing chunk: {i}')\n",
    "    chunk.to_csv(f'/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/sentiment_dataframes/chunk_{i}.csv')\n",
    "    print(f'Successfully finished chunk: {i}')\n",
    "    now = datetime.now()\n",
    "    ending_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Ending Time =\", ending_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T11:15:27.563385Z",
     "start_time": "2023-11-12T21:39:29.993871Z"
    }
   },
   "id": "5f01f491ab040894"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Path to the directory\n",
    "path = '/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/sentiment_dataframes/'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "all_files = glob.glob(path + \"*.csv\")\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file and append to the list\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:18.548845Z",
     "start_time": "2023-11-13T13:52:08.506645Z"
    }
   },
   "id": "168cd5516f24d0a4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Combine all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:18.926500Z",
     "start_time": "2023-11-13T13:52:18.551267Z"
    }
   },
   "id": "c82662f7331a1377"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "sentiment_df = combined_df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:19.167202Z",
     "start_time": "2023-11-13T13:52:18.929824Z"
    }
   },
   "id": "c2b2fb84f1507f90"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(4530623, 15)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:19.173596Z",
     "start_time": "2023-11-13T13:52:19.169458Z"
    }
   },
   "id": "4d9a59b65a11c3c6"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0           0\nSitzung              0\nDate                 0\nStart                0\nSchluss              0\nSpeaker              0\nText_Spoken          0\nReactions      3816713\nName                 0\nFraktion_x           0\nPosition             0\nWahlperiode          0\npositive             0\nnegative             0\nneutral              0\ndtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:39.931833Z",
     "start_time": "2023-11-13T13:52:37.744674Z"
    }
   },
   "id": "5b9f4581474aeae8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/speeches_bundestag/Final_DF/sentiment_analysis_all.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:53:02.134779Z",
     "start_time": "2023-11-13T13:52:39.931546Z"
    }
   },
   "id": "7b8993cef8d91456"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
