{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel\n",
    "import pandas as pd\n",
    "import os\n",
    "# Set TOKENIZERS_PARALLELISM to false before importing the tokenizers\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T11:15:27.580815Z",
     "start_time": "2023-11-13T11:15:27.557695Z"
    }
   },
   "id": "d36693109496cfa9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = SentimentModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:27.228886Z",
     "start_time": "2023-11-11T10:44:25.802345Z"
    }
   },
   "id": "49d14ca4c1dc2936"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"//Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/speeches_bundestag/Final_DF/combined_df_2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:35.886186Z",
     "start_time": "2023-11-11T10:44:27.229535Z"
    }
   },
   "id": "28ea2486bd2a7497"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46dfc21724f838c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Reset the index of the dataframe\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:36.235558Z",
     "start_time": "2023-11-11T10:44:35.887236Z"
    }
   },
   "id": "6a617e8835e4cf09"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'Wahlperiode_x', 'Fraktion_y', 'Wahlperiode_y'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:36.603934Z",
     "start_time": "2023-11-11T10:44:36.240431Z"
    }
   },
   "id": "ddbe6464c20d5f22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline and function to process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1fc8ead888492d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.608643Z",
     "start_time": "2023-11-11T10:44:36.604529Z"
    }
   },
   "id": "fca1c323e6108958"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('lxyuan/distilbert-base-multilingual-cased-sentiments-student')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.762566Z",
     "start_time": "2023-11-11T10:44:38.609408Z"
    }
   },
   "id": "7a5f266abb2c281a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# This is the final one I can use!\n",
    "# Assuming sentiment_pipeline is a predefined function that outputs the sentiment analysis in the list of dictionaries format\n",
    "\n",
    "def split_into_chunks(text, chunk_size=512):\n",
    "    # Split text into chunks of max_length only if it's longer than max_length\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)] if len(text) > chunk_size else [text]\n",
    "\n",
    "def get_sentiment(text, sentiment_pipeline):\n",
    "    # Split the text into chunks if necessary and get sentiment for each chunk\n",
    "    chunks = split_into_chunks(text)\n",
    "    chunk_sentiments = [sentiment_pipeline(chunk) for chunk in chunks]\n",
    "    return chunk_sentiments, chunks\n",
    "\n",
    "def unpack_sentiments(sentiment_data):\n",
    "    chunk_sentiments, chunks = sentiment_data\n",
    "    # Calculate the total length of the text to determine the weights\n",
    "    total_length = sum(len(chunk) for chunk in chunks)\n",
    "    # Initialize a dictionary with default scores\n",
    "    weighted_scores = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    # Calculate weighted scores\n",
    "    for sentiments, chunk in zip(chunk_sentiments, chunks):\n",
    "        chunk_weight = len(chunk) / total_length\n",
    "        for sentiment in sentiments[0]:\n",
    "            label = sentiment['label'].lower()  # Convert label to lowercase to match the keys in scores\n",
    "            # Add the weighted score\n",
    "            weighted_scores[label] += sentiment['score'] * chunk_weight\n",
    "    return pd.Series(weighted_scores)\n",
    "\n",
    "def weighted_sentiment_analysis_3(df, sentiment_pipeline):\n",
    "    # Apply the sentiment pipeline to the 'Text_Spoken' column, splitting into chunks if necessary\n",
    "    df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n",
    "\n",
    "    # Split the sentiment scores into separate columns with weighted averaging\n",
    "    sentiments_df = df['Sentiment_Data'].apply(unpack_sentiments)\n",
    "    df = df.join(sentiments_df)\n",
    "\n",
    "    # Drop the 'Sentiment_Data' column as it's no longer needed\n",
    "    df.drop(columns=['Sentiment_Data'], inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.768585Z",
     "start_time": "2023-11-11T10:44:38.764707Z"
    }
   },
   "id": "54d16d35dba9a3e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use chunks of 100 000 sentences and combine them later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a163c213224e3205"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started chunk: 3500000\n",
      "Starting Time = 22:39:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3500000\n",
      "Successfully finished chunk: 3500000\n",
      "Ending Time = 01:22:12\n",
      "Started chunk: 3600000\n",
      "Starting Time = 01:22:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3600000\n",
      "Successfully finished chunk: 3600000\n",
      "Ending Time = 04:41:09\n",
      "Started chunk: 3700000\n",
      "Starting Time = 04:41:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3700000\n",
      "Successfully finished chunk: 3700000\n",
      "Ending Time = 08:01:37\n",
      "Started chunk: 3800000\n",
      "Starting Time = 08:01:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3800000\n",
      "Successfully finished chunk: 3800000\n",
      "Ending Time = 08:59:59\n",
      "Started chunk: 3900000\n",
      "Starting Time = 08:59:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 3900000\n",
      "Successfully finished chunk: 3900000\n",
      "Ending Time = 09:30:16\n",
      "Started chunk: 4000000\n",
      "Starting Time = 09:30:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4000000\n",
      "Successfully finished chunk: 4000000\n",
      "Ending Time = 10:00:47\n",
      "Started chunk: 4100000\n",
      "Starting Time = 10:00:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4100000\n",
      "Successfully finished chunk: 4100000\n",
      "Ending Time = 10:31:50\n",
      "Started chunk: 4200000\n",
      "Starting Time = 10:31:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4200000\n",
      "Successfully finished chunk: 4200000\n",
      "Ending Time = 11:02:38\n",
      "Started chunk: 4300000\n",
      "Starting Time = 11:02:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4300000\n",
      "Successfully finished chunk: 4300000\n",
      "Ending Time = 11:34:15\n",
      "Started chunk: 4400000\n",
      "Starting Time = 11:34:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4400000\n",
      "Successfully finished chunk: 4400000\n",
      "Ending Time = 12:06:03\n",
      "Started chunk: 4500000\n",
      "Starting Time = 12:06:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/lk9jxn256x10l_m01pz7khdw0000gn/T/ipykernel_39531/2531332682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chunk: 4500000\n",
      "Successfully finished chunk: 4500000\n",
      "Ending Time = 12:15:27\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into chunks of 100000 lines\n",
    "for i in range(3500000, len(df), 100000):\n",
    "    print(f'Started chunk: {i}')\n",
    "    now = datetime.now()\n",
    "    starting_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Starting Time =\", starting_time)\n",
    "    chunk = df[i:i+100000]\n",
    "    chunk = weighted_sentiment_analysis_3(chunk, sentiment_pipeline)\n",
    "    print(f'Writing chunk: {i}')\n",
    "    chunk.to_csv(f'/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/sentiment_dataframes/chunk_{i}.csv')\n",
    "    print(f'Successfully finished chunk: {i}')\n",
    "    now = datetime.now()\n",
    "    ending_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Ending Time =\", ending_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T11:15:27.563385Z",
     "start_time": "2023-11-12T21:39:29.993871Z"
    }
   },
   "id": "5f01f491ab040894"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Path to the directory\n",
    "path = '/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/sentiment_dataframes/'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "all_files = glob.glob(path + \"*.csv\")\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file and append to the list\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:18.548845Z",
     "start_time": "2023-11-13T13:52:08.506645Z"
    }
   },
   "id": "168cd5516f24d0a4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Combine all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:18.926500Z",
     "start_time": "2023-11-13T13:52:18.551267Z"
    }
   },
   "id": "c82662f7331a1377"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "sentiment_df = combined_df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:19.167202Z",
     "start_time": "2023-11-13T13:52:18.929824Z"
    }
   },
   "id": "c2b2fb84f1507f90"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(4530623, 15)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:19.173596Z",
     "start_time": "2023-11-13T13:52:19.169458Z"
    }
   },
   "id": "4d9a59b65a11c3c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some Cleaning I realised"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6550b0801fc435c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- in a sentence all after: Geschiedenen Drucksachen\n",
    "- all of these: 17/3871,\n",
    "- and all of these 17/3871"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d06706b660322f25"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Splitting each string in 'your_column' at the pattern and keeping only the part before it\n",
    "sentiment_df['Text_Spoken'] = sentiment_df['Text_Spoken'].apply(lambda x: x.split('Geschiedenen Drucksachen')[0] + '.' if 'Geschiedenen Drucksachen' in x else x)\n",
    "sentiment_df['Text_Spoken'] = sentiment_df['Text_Spoken'].apply(lambda x: x.split('Drucksachen')[0] + '.' if 'Geschiedenen Drucksachen' in x else x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:26.344777Z",
     "start_time": "2023-11-13T13:52:24.904533Z"
    }
   },
   "id": "aca12ae1d6de9336"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "sentiment_df['Text_Spoken'] = sentiment_df['Text_Spoken'].replace('\\d{2}\\/\\d{4}\\,', '', regex=True)\n",
    "sentiment_df['Text_Spoken'] = sentiment_df['Text_Spoken'].replace('\\d{2}\\/\\d{4}', '', regex=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:37.743686Z",
     "start_time": "2023-11-13T13:52:26.346066Z"
    }
   },
   "id": "6bfaa8fe36486070"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0           0\nSitzung              0\nDate                 0\nStart                0\nSchluss              0\nSpeaker              0\nText_Spoken          0\nReactions      3816713\nName                 0\nFraktion_x           0\nPosition             0\nWahlperiode          0\npositive             0\nnegative             0\nneutral              0\ndtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:52:39.931833Z",
     "start_time": "2023-11-13T13:52:37.744674Z"
    }
   },
   "id": "5b9f4581474aeae8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/speeches_bundestag/Final_DF/sentiment_analysis_all.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:53:02.134779Z",
     "start_time": "2023-11-13T13:52:39.931546Z"
    }
   },
   "id": "7b8993cef8d91456"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "88b2b9bd348adc4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
