{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel\n",
    "import pandas as pd\n",
    "import os\n",
    "# Set TOKENIZERS_PARALLELISM to false before importing the tokenizers\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:25.801375Z",
     "start_time": "2023-11-11T10:44:14.710266Z"
    }
   },
   "id": "d36693109496cfa9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = SentimentModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:27.228886Z",
     "start_time": "2023-11-11T10:44:25.802345Z"
    }
   },
   "id": "49d14ca4c1dc2936"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"//Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/speeches_bundestag/Final_DF/combined_df_2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:35.886186Z",
     "start_time": "2023-11-11T10:44:27.229535Z"
    }
   },
   "id": "28ea2486bd2a7497"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46dfc21724f838c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Reset the index of the dataframe\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:36.235558Z",
     "start_time": "2023-11-11T10:44:35.887236Z"
    }
   },
   "id": "6a617e8835e4cf09"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'Wahlperiode_x', 'Fraktion_y', 'Wahlperiode_y'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:36.603934Z",
     "start_time": "2023-11-11T10:44:36.240431Z"
    }
   },
   "id": "ddbe6464c20d5f22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline and function to process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1fc8ead888492d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.608643Z",
     "start_time": "2023-11-11T10:44:36.604529Z"
    }
   },
   "id": "fca1c323e6108958"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('lxyuan/distilbert-base-multilingual-cased-sentiments-student')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.762566Z",
     "start_time": "2023-11-11T10:44:38.609408Z"
    }
   },
   "id": "7a5f266abb2c281a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# This is the final one I can use!\n",
    "# Assuming sentiment_pipeline is a predefined function that outputs the sentiment analysis in the list of dictionaries format\n",
    "\n",
    "def split_into_chunks(text, chunk_size=512):\n",
    "    # Split text into chunks of max_length only if it's longer than max_length\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)] if len(text) > chunk_size else [text]\n",
    "\n",
    "def get_sentiment(text, sentiment_pipeline):\n",
    "    # Split the text into chunks if necessary and get sentiment for each chunk\n",
    "    chunks = split_into_chunks(text)\n",
    "    chunk_sentiments = [sentiment_pipeline(chunk) for chunk in chunks]\n",
    "    return chunk_sentiments, chunks\n",
    "\n",
    "def unpack_sentiments(sentiment_data):\n",
    "    chunk_sentiments, chunks = sentiment_data\n",
    "    # Calculate the total length of the text to determine the weights\n",
    "    total_length = sum(len(chunk) for chunk in chunks)\n",
    "    # Initialize a dictionary with default scores\n",
    "    weighted_scores = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    # Calculate weighted scores\n",
    "    for sentiments, chunk in zip(chunk_sentiments, chunks):\n",
    "        chunk_weight = len(chunk) / total_length\n",
    "        for sentiment in sentiments[0]:\n",
    "            label = sentiment['label'].lower()  # Convert label to lowercase to match the keys in scores\n",
    "            # Add the weighted score\n",
    "            weighted_scores[label] += sentiment['score'] * chunk_weight\n",
    "    return pd.Series(weighted_scores)\n",
    "\n",
    "def weighted_sentiment_analysis_3(df, sentiment_pipeline):\n",
    "    # Apply the sentiment pipeline to the 'Text_Spoken' column, splitting into chunks if necessary\n",
    "    df['Sentiment_Data'] = df['Text_Spoken'].apply(lambda text: get_sentiment(text, sentiment_pipeline))\n",
    "\n",
    "    # Split the sentiment scores into separate columns with weighted averaging\n",
    "    sentiments_df = df['Sentiment_Data'].apply(unpack_sentiments)\n",
    "    df = df.join(sentiments_df)\n",
    "\n",
    "    # Drop the 'Sentiment_Data' column as it's no longer needed\n",
    "    df.drop(columns=['Sentiment_Data'], inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T10:44:38.768585Z",
     "start_time": "2023-11-11T10:44:38.764707Z"
    }
   },
   "id": "54d16d35dba9a3e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use chunks of 100 000 sentences and combine them later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a163c213224e3205"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started chunk: 1100000\n",
      "Starting Time = 11:44:43\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into chunks of 100000 lines\n",
    "for i in range(1100000, len(df), 100000):\n",
    "    print(f'Started chunk: {i}')\n",
    "    now = datetime.now()\n",
    "    starting_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Starting Time =\", starting_time)\n",
    "    chunk = df[i:i+10000]\n",
    "    chunk = weighted_sentiment_analysis_3(chunk, sentiment_pipeline)\n",
    "    print(f'Writing chunk: {i}')\n",
    "    chunk.to_csv(f'/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/sentiment_dataframes/chunk_{i}.csv')\n",
    "    print(f'Successfully finished chunk: {i}')\n",
    "    now = datetime.now()\n",
    "    ending_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Ending Time =\", ending_time)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-11T10:44:43.176680Z"
    }
   },
   "id": "5f01f491ab040894"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine the split dataframes back together\n",
    "combined_df = pd.read_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/sentiment_dataframes/*.csv')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "168cd5516f24d0a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_df = combined_df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T07:59:32.864869Z",
     "start_time": "2023-11-08T07:59:32.850194Z"
    }
   },
   "id": "c2b2fb84f1507f90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Final_Project/speeches_bundestag/Final_DF/sentiment_analysis_all.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T07:59:32.851858Z"
    }
   },
   "id": "7b8993cef8d91456"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
