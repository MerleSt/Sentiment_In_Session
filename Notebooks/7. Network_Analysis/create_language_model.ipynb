{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:37:35.879538Z",
     "start_time": "2023-11-14T15:37:35.878577Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:38:06.334308Z",
     "start_time": "2023-11-14T15:38:05.060531Z"
    }
   },
   "id": "d32f1391fa97be95"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/sentiment_analysis_all.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:37:45.496910Z",
     "start_time": "2023-11-14T15:37:35.880923Z"
    }
   },
   "id": "6d477b0eb2ff688a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = df_sentiment.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:37:45.747775Z",
     "start_time": "2023-11-14T15:37:45.496810Z"
    }
   },
   "id": "93981dd14f9de5c7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Filter speakers with at least 2000 sentences\n",
    "speaker_counts = df['Name'].value_counts()\n",
    "selected_speakers = speaker_counts[speaker_counts >= 2000].index\n",
    "filtered_df = df[df['Name'].isin(selected_speakers)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:38:31.129245Z",
     "start_time": "2023-11-14T15:38:30.732302Z"
    }
   },
   "id": "dfd1f97f62545fe"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(722,)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_speakers.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:38:52.074282Z",
     "start_time": "2023-11-14T15:38:52.066603Z"
    }
   },
   "id": "2f8160b2d81e05dc"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Combine text for each speaker\n",
    "speaker_texts = filtered_df.groupby('Name')['Text_Spoken'].apply(' '.join)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:39:13.751308Z",
     "start_time": "2023-11-14T15:39:12.742571Z"
    }
   },
   "id": "c68e029af4a7b2a2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e772be266ae747a990cc4ca5ad96af61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90950e80cb7e4661aced432d09ae9312"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a63f43ea1d194e2695731807217c2368"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b358db897294903b4600a2bc8484761"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "739b5634c51b414e92f51a5a71371915"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05c400455a4f47d0ae3cd5620d1d5cb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Fine-tuning process (high-level)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:39:50.974311Z",
     "start_time": "2023-11-14T15:39:23.827104Z"
    }
   },
   "id": "750925f5d1381834"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Let us train GPT on our speakers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1922bed957614e3f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Name\nAgnieszka Brugger           Herr Präsident! Meine Damen und Herren! In kei...\nAlbert Rupprecht(Weiden)    Sehr geehrte Frau Präsidentin! Liebe Kolleginn...\nAlbrecht Glaser             Herr Präsident! Meine sehr verehrten Damen und...\nAlexander Bonde             Herr Präsident! Verehrte Damen und Herren! Lie...\nAlexander Dobrindt          Herr Präsident! Sehr geehrte Damen und Herren!...\n                                                  ...                        \nWolfgang Wiehle             Sehr geehrter Herr Präsident! Kolleginnen und ...\nWolfgang Wieland            Frau Staatsekretärin, grüne Parlamentarier sin...\nWolfgang Zöller             Grüß Gott, Herr Präsident! Liebe Kolleginnen u...\nYvonne Magwas               Sehr geehrter Herr Präsident! Liebe Kolleginne...\nÖzcan Mutlu                 Sehr geehrter Herr Präsident! Liebe Kolleginne...\nName: Text_Spoken, Length: 722, dtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_texts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:41:50.332007Z",
     "start_time": "2023-11-14T15:41:50.330151Z"
    }
   },
   "id": "7b64352abe44b7b4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:42:42.005928Z",
     "start_time": "2023-11-14T15:42:41.994536Z"
    }
   },
   "id": "e9988533361bb7e2"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class SpeakerDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        return {'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:58:01.220599Z",
     "start_time": "2023-11-14T15:58:01.218443Z"
    }
   },
   "id": "2e17987dabfcadcb"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "dataset = SpeakerDataset(speaker_texts, tokenizer, max_length=512)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:58:01.676161Z",
     "start_time": "2023-11-14T15:58:01.671525Z"
    }
   },
   "id": "91b9d8d24e0d0fa"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_linear_schedule_with_warmup"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:59:07.744478Z",
     "start_time": "2023-11-14T15:59:07.736803Z"
    }
   },
   "id": "d2b58ee6b251d17a"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:59:44.632889Z",
     "start_time": "2023-11-14T15:59:44.622414Z"
    }
   },
   "id": "5957414560abb29a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Function for training one epoch\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = input_ids.clone()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return total_loss / len(data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:59:46.799169Z",
     "start_time": "2023-11-14T15:59:46.797920Z"
    }
   },
   "id": "55377f75ca74eb77"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Function for evaluating the model\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = input_ids.clone()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:59:47.045130Z",
     "start_time": "2023-11-14T15:59:47.043397Z"
    }
   },
   "id": "d4adf3c972bc3ad4"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and validation\n",
    "epochs = 4  # Choose the number of epochs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T16:00:28.950480Z",
     "start_time": "2023-11-14T16:00:28.940390Z"
    }
   },
   "id": "9c88f9602a4e2c6a"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Assuming you have a 'dataset' variable which is an instance of your custom Dataset class\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)  # No need to shuffle the validation set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T16:38:13.970565Z",
     "start_time": "2023-11-14T16:38:13.960284Z"
    }
   },
   "id": "502ab3b6a06c027c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set pad_token to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss = evaluate_model(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/training_models_on_politicians')\n",
    "tokenizer.save_pretrained('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/training_models_on_politicians')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-14T16:38:15.882593Z"
    }
   },
   "id": "8ec9d09303b4c15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "275930dcc397c92f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/training_models_on_politicians/model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/training_models_on_politicians.tokenizer')\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(prompt, length=50):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    attention_mask = torch.ones(input_ids.shape, device=input_ids.device)\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=length, num_return_sequences=1)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Here is a sentence to start off\"  # Replace with your own prompt\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4c2d2ace1969000"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
