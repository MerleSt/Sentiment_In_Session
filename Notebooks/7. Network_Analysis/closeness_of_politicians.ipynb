{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:32:32.091389Z",
     "start_time": "2023-11-15T14:32:32.050902Z"
    }
   },
   "id": "efdadd25dda2fef9"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:32:35.522603Z",
     "start_time": "2023-11-15T14:32:33.770987Z"
    }
   },
   "id": "b8551c03c68f8f3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataframe work"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9552657cdc23efc8"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/sentiment_analysis_all.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:32:45.155202Z",
     "start_time": "2023-11-15T14:32:35.526998Z"
    }
   },
   "id": "97c661f4e9a6dce1"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "df_full['Party'] = df_full['Party'].replace('Bündnis 90/Die Grünen', 'Die Grünen')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:29:08.861138Z",
     "start_time": "2023-11-08T14:29:07.841308Z"
    }
   },
   "id": "e22871a29f14d714"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Heatmap"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117c1b68be970d8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "heatmap of top 5 speakers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "200c9de616aab309"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c8ac6f9140c86038"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "                     Name                                        Text_Spoken\n0        Wolfgang Kubicki                    Der Antrag ist damit abgelehnt.\n1        Wolfgang Kubicki  Endgültiges Ergebnis Abgegebene Stimmen: 633;d...\n2        Wolfgang Kubicki  Sybille Benning Dr André Berghegger Melanie Be...\n3        Wolfgang Kubicki  Dr Reinhard Brandl Sebastian Brehm Heike Brehm...\n4        Wolfgang Kubicki                          Fischer (Karlsruhe Land).\n...                   ...                                                ...\n4530563         Petra Pau      Frau Kollegin, achten Sie bitte auf die Zeit.\n4530566         Petra Pau  Sie haben alle Chancen, das nachher zum nächst...\n4530567         Petra Pau                 Sie müssen jetzt zum Punkt kommen.\n4530573         Petra Pau  Das Wort hat die Kollegin Kerstin Tack für die...\n4530614         Petra Pau  Das Wort hat die Kollegin Dr Astrid Freudenste...\n\n[282701 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Text_Spoken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Der Antrag ist damit abgelehnt.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Endgültiges Ergebnis Abgegebene Stimmen: 633;d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Sybille Benning Dr André Berghegger Melanie Be...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Dr Reinhard Brandl Sebastian Brehm Heike Brehm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Fischer (Karlsruhe Land).</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4530563</th>\n      <td>Petra Pau</td>\n      <td>Frau Kollegin, achten Sie bitte auf die Zeit.</td>\n    </tr>\n    <tr>\n      <th>4530566</th>\n      <td>Petra Pau</td>\n      <td>Sie haben alle Chancen, das nachher zum nächst...</td>\n    </tr>\n    <tr>\n      <th>4530567</th>\n      <td>Petra Pau</td>\n      <td>Sie müssen jetzt zum Punkt kommen.</td>\n    </tr>\n    <tr>\n      <th>4530573</th>\n      <td>Petra Pau</td>\n      <td>Das Wort hat die Kollegin Kerstin Tack für die...</td>\n    </tr>\n    <tr>\n      <th>4530614</th>\n      <td>Petra Pau</td>\n      <td>Das Wort hat die Kollegin Dr Astrid Freudenste...</td>\n    </tr>\n  </tbody>\n</table>\n<p>282701 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_count = df_full.groupby('Name').size().sort_values(ascending=False)\n",
    "\n",
    "# Get the top 5 speakers\n",
    "top_speakers = sentence_count.head(5).index\n",
    "\n",
    "# Filter the original dataframe for only the top 5 speakers\n",
    "# and select only 'Name' and 'Text_Spoken' columns\n",
    "example_df = df_full[df_full['Name'].isin(top_speakers)][['Name', 'Text_Spoken']]\n",
    "\n",
    "# Display the resulting dataframe\n",
    "example_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:40:56.503505Z",
     "start_time": "2023-11-15T14:40:56.243880Z"
    }
   },
   "id": "5c99d624b44b22b2"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Encode the sentences to get the embeddings\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m example_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m example_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mText_Spoken\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: model\u001B[38;5;241m.\u001B[39mencode(x))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Group by speaker and average their sentence embeddings\u001B[39;00m\n\u001B[1;32m      5\u001B[0m speaker_embeddings \u001B[38;5;241m=\u001B[39m example_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSpeaker\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbeddings\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mmean())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4668\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4670\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SeriesApply(\u001B[38;5;28mself\u001B[39m, func, convert_dtype, args, kwargs)\u001B[38;5;241m.\u001B[39mapply()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1122\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1172\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1173\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1174\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mmap_infer(\n\u001B[1;32m   1175\u001B[0m             values,\n\u001B[1;32m   1176\u001B[0m             f,\n\u001B[1;32m   1177\u001B[0m             convert\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_dtype,\n\u001B[1;32m   1178\u001B[0m         )\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1182\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[48], line 2\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Encode the sentences to get the embeddings\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m example_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m example_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mText_Spoken\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: model\u001B[38;5;241m.\u001B[39mencode(x))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Group by speaker and average their sentence embeddings\u001B[39;00m\n\u001B[1;32m      5\u001B[0m speaker_embeddings \u001B[38;5;241m=\u001B[39m example_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSpeaker\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbeddings\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mmean())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:165\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[1;32m    162\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 165\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(features)\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    168\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:66\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[1;32m     64\u001B[0m     trans_features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 66\u001B[0m output_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrans_features, return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     67\u001B[0m output_tokens \u001B[38;5;241m=\u001B[39m output_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     69\u001B[0m features\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m: output_tokens, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:609\u001B[0m, in \u001B[0;36mDistilBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    605\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m    607\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(input_ids, inputs_embeds)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m--> 609\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer(\n\u001B[1;32m    610\u001B[0m     x\u001B[38;5;241m=\u001B[39membeddings,\n\u001B[1;32m    611\u001B[0m     attn_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    612\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[1;32m    613\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    614\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    615\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    616\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:375\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    368\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    369\u001B[0m         create_custom_forward(layer_module),\n\u001B[1;32m    370\u001B[0m         hidden_state,\n\u001B[1;32m    371\u001B[0m         attn_mask,\n\u001B[1;32m    372\u001B[0m         head_mask[i],\n\u001B[1;32m    373\u001B[0m     )\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 375\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[1;32m    376\u001B[0m         hidden_state,\n\u001B[1;32m    377\u001B[0m         attn_mask,\n\u001B[1;32m    378\u001B[0m         head_mask[i],\n\u001B[1;32m    379\u001B[0m         output_attentions,\n\u001B[1;32m    380\u001B[0m     )\n\u001B[1;32m    382\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:313\u001B[0m, in \u001B[0;36mTransformerBlock.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    310\u001B[0m sa_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msa_layer_norm(sa_output \u001B[38;5;241m+\u001B[39m x)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;66;03m# Feed Forward Network\u001B[39;00m\n\u001B[0;32m--> 313\u001B[0m ffn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn(sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    314\u001B[0m ffn_output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_layer_norm(ffn_output \u001B[38;5;241m+\u001B[39m sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    316\u001B[0m output \u001B[38;5;241m=\u001B[39m (ffn_output,)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:254\u001B[0m, in \u001B[0;36mFFN.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m apply_chunking_to_forward(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mff_chunk, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_size_feed_forward, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseq_len_dim, \u001B[38;5;28minput\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/pytorch_utils.py:240\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[0;32m--> 240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m forward_fn(\u001B[38;5;241m*\u001B[39minput_tensors)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:257\u001B[0m, in \u001B[0;36mFFN.ff_chunk\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mff_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 257\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin1(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    258\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(x)\n\u001B[1;32m    259\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin2(x)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Encode the sentences to get the embeddings\n",
    "example_df['Embeddings'] = example_df['Text_Spoken'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Group by speaker and average their sentence embeddings\n",
    "speaker_embeddings = example_df.groupby('Speaker')['Embeddings'].apply(lambda x: x.mean())\n",
    "\n",
    "# Calculate the cosine similarity between each speaker's average embedding\n",
    "similarity_matrix = cosine_similarity(list(speaker_embeddings))\n",
    "\n",
    "# Convert the similarity matrix into a dataframe\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=speaker_embeddings.index, columns=speaker_embeddings.index)\n",
    "\n",
    "# Visualize the similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_df, annot=True)\n",
    "plt.title('Speaker Similarity Heatmap')\n",
    "plt.savefig('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Präsentation/Graphs/heatmap.png')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:25:53.056015Z",
     "start_time": "2023-11-15T14:41:06.611292Z"
    }
   },
   "id": "f21dc89c49f045c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spacy model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab55a402068039d"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_lg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:25:57.298083Z",
     "start_time": "2023-11-15T17:25:55.737557Z"
    }
   },
   "id": "40121d825c876053"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Let us add the Party"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6adfbdc9659f10c"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df1 = df_full.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T17:25:57.863875Z",
     "start_time": "2023-11-15T17:25:57.299024Z"
    }
   },
   "id": "b484663e3de6ff0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Chunky chunk chunk\n",
    "# Group by speaker and concatenate all text spoken by the same speaker\n",
    "grouped_df = df1.groupby('Name')['Text_Spoken'].apply(' '.join).reset_index()\n",
    "\n",
    "# Add the 'Party' column to the grouped_df\n",
    "grouped_df = grouped_df.merge(df1[['Name', 'Party']].drop_duplicates(), on='Name')\n",
    "\n",
    "# Function to process text in chunks\n",
    "def process_text_in_chunks(text, chunk_size=1000000):\n",
    "    # Process the text in chunks of the given size\n",
    "    doc = nlp(text[:chunk_size])\n",
    "    processed_text = ' '.join([token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and token.is_alpha])\n",
    "    for i in range(chunk_size, len(text), chunk_size):\n",
    "        doc = nlp(text[i:i+chunk_size])\n",
    "        processed_text += ' ' + ' '.join([token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and token.is_alpha])\n",
    "    return processed_text\n",
    "\n",
    "# Apply preprocessing to the grouped DataFrame\n",
    "grouped_df['Processed_Text'] = grouped_df['Text_Spoken'].apply(lambda text: process_text_in_chunks(text))\n",
    "\n",
    "# Vectorize the text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(grouped_df['Processed_Text'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Convert cosine similarity matrix to DataFrame\n",
    "cosine_sim_df_text = pd.DataFrame(cosine_sim, index=grouped_df['Name'], columns=grouped_df['Name'])\n",
    "\n",
    "# Display the similarity matrix\n",
    "cosine_sim_df_text"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-15T17:26:02.261433Z"
    }
   },
   "id": "6ec160b48a541a23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the cosine similarity matrix to a CSV file\n",
    "cosine_sim_df_text.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/cosine_similarity_matrix.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a70c0eb6137a3a34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "party_colors_map = {\n",
    "    'SPD': 'red',\n",
    "    'PDS': '#801818',\n",
    "    'CDU': 'white',\n",
    "    'FDP': 'yellow',\n",
    "    'Die Grünen': 'green',\n",
    "    'CSU': 'white',\n",
    "    'AfD': '#0489DB',\n",
    "    'Die Linke': 'pink',\n",
    "    'fraktionslos': 'white',\n",
    "    'LKR': '#FE8100',\n",
    "    'SSW': '#00277E'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "84002c045f87370f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and associate each node with a party\n",
    "for index, row in grouped_df.iterrows():\n",
    "    G.add_node(row['Name'], party=row['Party'])\n",
    "\n",
    "# Get a list of colors for each node\n",
    "node_colors = party_colors_map\n",
    "\n",
    "# Define a threshold for similarity to draw an edge\n",
    "threshold = 0.6  # You may need to adjust this value\n",
    "\n",
    "# Add edges to the graph\n",
    "for i, speaker1 in enumerate(cosine_sim_df_text.index):\n",
    "    for j, speaker2 in enumerate(cosine_sim_df_text.columns):\n",
    "        if i < j:  # This ensures that each pair is only considered once\n",
    "            similarity = cosine_sim_df_text.iloc[i, j]\n",
    "            if similarity > threshold:\n",
    "                G.add_edge(speaker1, speaker2, weight=similarity)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(20, 10), facecolor='#282828')\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "#pos = nx.spring_layout(G, k=0.1)  # k is the optimal distance between nodes, may need to be adjusted\n",
    "\n",
    "# Create a subgraph of G that only includes the largest connected component\n",
    "# If you want to include smaller connected components as well, you can adjust this part\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "subgraph = G.subgraph(largest_cc)\n",
    "\n",
    "# Draw only the nodes and edges from the largest connected component\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color=[party_colors_map[subgraph.nodes[speaker]['party']] for speaker in subgraph.nodes], alpha=0.7, node_size=590)  # Adjust node_size as needed\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='gray', alpha=0.5, width=0.5)\n",
    "\n",
    "\n",
    "# Create a legend for the color map\n",
    "party_labels = list(party_colors_map.keys())\n",
    "patches = [plt.Line2D([0], [0], marker='o', color='w', label=party,\n",
    "                      markersize=10, markerfacecolor=color) for party, color in party_colors_map.items()]\n",
    "plt.legend(handles=patches, title=\"Political Parties\", loc='upper left', bbox_to_anchor=(1, 1), fontsize='large')\n",
    "\n",
    "plt.title('Network Graph of Speaker Similarity',  fontsize=20, loc='center', color='white')\n",
    "plt.axis('off')\n",
    "plt.savefig('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Präsentation/Graphs/speaker_similarity_graph_1.png', dpi=300, bbox_inches='tight', facecolor='#282828')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fd2a41ce505edffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Networkgraph Based on Sentiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f0b9d6e4930009a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Group by 'Name' and calculate the mean of each sentiment\n",
    "grouped_sentiment_df = df1.groupby('Name')[['positive', 'neutral', 'negative']].mean().reset_index()\n",
    "\n",
    "# Add the 'Party' column to the grouped_df before creating the sentiment matrix\n",
    "grouped_sentiment_df = grouped_sentiment_df.merge(df1[['Name', 'Party']].drop_duplicates(), on='Name')\n",
    "\n",
    "# Create the sentiment matrix from the grouped DataFrame\n",
    "sentiment_matrix = grouped_sentiment_df[['positive', 'neutral', 'negative']].values\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim_sentiment = cosine_similarity(sentiment_matrix, sentiment_matrix)\n",
    "\n",
    "# Convert cosine similarity matrix to DataFrame\n",
    "cosine_sim_df_sentiment = pd.DataFrame(cosine_sim_sentiment, \n",
    "                                       index=grouped_sentiment_df['Name'], \n",
    "                                       columns=grouped_sentiment_df['Name'])\n",
    "\n",
    "# Display the similarity matrix\n",
    "cosine_sim_df_sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bfede61cf6adf7f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the cosine similarity matrix to a CSV file\n",
    "cosine_sim_df_sentiment.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/cosine_sim_df_sentiment.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "23fd3b40cf57ab94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and associate each node with a party\n",
    "for index, row in grouped_sentiment_df.iterrows():\n",
    "    G.add_node(row['Name'], party=row['Party'])\n",
    "\n",
    "# Get a list of colors for each node\n",
    "node_colors = party_colors_map\n",
    "\n",
    "# Define a threshold for similarity to draw an edge\n",
    "threshold = 0.999  # You may need to adjust this value\n",
    "\n",
    "# Add edges to the graph\n",
    "for i, speaker1 in enumerate(cosine_sim_df_sentiment.index):\n",
    "    for j, speaker2 in enumerate(cosine_sim_df_sentiment.columns):\n",
    "        if i < j:  # This ensures that each pair is only considered once\n",
    "            similarity = cosine_sim_df_sentiment.iloc[i, j]\n",
    "            if similarity > threshold:\n",
    "                G.add_edge(speaker1, speaker2, weight=similarity)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(20, 10), facecolor='#282828')\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "#pos = nx.spring_layout(G, k=0.1)  # k is the optimal distance between nodes, may need to be adjusted\n",
    "\n",
    "# Create a subgraph of G that only includes the largest connected component\n",
    "# If you want to include smaller connected components as well, you can adjust this part\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "subgraph = G.subgraph(largest_cc)\n",
    "\n",
    "# Draw only the nodes and edges from the largest connected component\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color=[party_colors_map[subgraph.nodes[speaker]['party']] for speaker in subgraph.nodes], alpha=0.7, node_size=100)  # Adjust node_size as needed\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='gray', alpha=0.5, width=0.5)\n",
    "\n",
    "\n",
    "# Create a legend for the color map\n",
    "party_labels = list(party_colors_map.keys())\n",
    "patches = [plt.Line2D([0], [0], marker='o', color='w', label=party,\n",
    "                      markersize=10, markerfacecolor=color) for party, color in party_colors_map.items()]\n",
    "plt.legend(handles=patches, title=\"Political Parties\", loc='upper left', bbox_to_anchor=(1, 1), fontsize='large')\n",
    "\n",
    "plt.title('Network Graph of Speaker Similarity',  fontsize=20, loc='center', color='white')\n",
    "plt.axis('off')\n",
    "plt.savefig('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Präsentation/Graphs/4.png', dpi=300, bbox_inches='tight', facecolor='#282828')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "47e991d377776b76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc14dbf57801d1d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
