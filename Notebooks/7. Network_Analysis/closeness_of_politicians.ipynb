{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:32:32.091389Z",
     "start_time": "2023-11-15T14:32:32.050902Z"
    }
   },
   "id": "efdadd25dda2fef9"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:32:35.522603Z",
     "start_time": "2023-11-15T14:32:33.770987Z"
    }
   },
   "id": "b8551c03c68f8f3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataframe work"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9552657cdc23efc8"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/sentiment_analysis_all.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:32:45.155202Z",
     "start_time": "2023-11-15T14:32:35.526998Z"
    }
   },
   "id": "97c661f4e9a6dce1"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "df_full['Party'] = df_full['Party'].replace('Bündnis 90/Die Grünen', 'Die Grünen')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:29:08.861138Z",
     "start_time": "2023-11-08T14:29:07.841308Z"
    }
   },
   "id": "e22871a29f14d714"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Heatmap"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117c1b68be970d8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "heatmap of top 5 speakers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "200c9de616aab309"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c8ac6f9140c86038"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "                     Name                                        Text_Spoken\n0        Wolfgang Kubicki                    Der Antrag ist damit abgelehnt.\n1        Wolfgang Kubicki  Endgültiges Ergebnis Abgegebene Stimmen: 633;d...\n2        Wolfgang Kubicki  Sybille Benning Dr André Berghegger Melanie Be...\n3        Wolfgang Kubicki  Dr Reinhard Brandl Sebastian Brehm Heike Brehm...\n4        Wolfgang Kubicki                          Fischer (Karlsruhe Land).\n...                   ...                                                ...\n4530563         Petra Pau      Frau Kollegin, achten Sie bitte auf die Zeit.\n4530566         Petra Pau  Sie haben alle Chancen, das nachher zum nächst...\n4530567         Petra Pau                 Sie müssen jetzt zum Punkt kommen.\n4530573         Petra Pau  Das Wort hat die Kollegin Kerstin Tack für die...\n4530614         Petra Pau  Das Wort hat die Kollegin Dr Astrid Freudenste...\n\n[282701 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Text_Spoken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Der Antrag ist damit abgelehnt.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Endgültiges Ergebnis Abgegebene Stimmen: 633;d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Sybille Benning Dr André Berghegger Melanie Be...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Dr Reinhard Brandl Sebastian Brehm Heike Brehm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wolfgang Kubicki</td>\n      <td>Fischer (Karlsruhe Land).</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4530563</th>\n      <td>Petra Pau</td>\n      <td>Frau Kollegin, achten Sie bitte auf die Zeit.</td>\n    </tr>\n    <tr>\n      <th>4530566</th>\n      <td>Petra Pau</td>\n      <td>Sie haben alle Chancen, das nachher zum nächst...</td>\n    </tr>\n    <tr>\n      <th>4530567</th>\n      <td>Petra Pau</td>\n      <td>Sie müssen jetzt zum Punkt kommen.</td>\n    </tr>\n    <tr>\n      <th>4530573</th>\n      <td>Petra Pau</td>\n      <td>Das Wort hat die Kollegin Kerstin Tack für die...</td>\n    </tr>\n    <tr>\n      <th>4530614</th>\n      <td>Petra Pau</td>\n      <td>Das Wort hat die Kollegin Dr Astrid Freudenste...</td>\n    </tr>\n  </tbody>\n</table>\n<p>282701 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_count = df_full.groupby('Name').size().sort_values(ascending=False)\n",
    "\n",
    "# Get the top 5 speakers\n",
    "top_speakers = sentence_count.head(5).index\n",
    "\n",
    "# Filter the original dataframe for only the top 5 speakers\n",
    "# and select only 'Name' and 'Text_Spoken' columns\n",
    "example_df = df_full[df_full['Name'].isin(top_speakers)][['Name', 'Text_Spoken']]\n",
    "\n",
    "# Display the resulting dataframe\n",
    "example_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T14:40:56.503505Z",
     "start_time": "2023-11-15T14:40:56.243880Z"
    }
   },
   "id": "5c99d624b44b22b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode the sentences to get the embeddings\n",
    "example_df['Embeddings'] = example_df['Text_Spoken'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Group by speaker and average their sentence embeddings\n",
    "speaker_embeddings = example_df.groupby('Speaker')['Embeddings'].apply(lambda x: x.mean())\n",
    "\n",
    "# Calculate the cosine similarity between each speaker's average embedding\n",
    "similarity_matrix = cosine_similarity(list(speaker_embeddings))\n",
    "\n",
    "# Convert the similarity matrix into a dataframe\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=speaker_embeddings.index, columns=speaker_embeddings.index)\n",
    "\n",
    "# Visualize the similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_df, annot=True)\n",
    "plt.title('Speaker Similarity Heatmap')\n",
    "plt.savefig('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Präsentation/Graphs/heatmap.png')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-15T14:41:06.611292Z"
    }
   },
   "id": "f21dc89c49f045c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spacy model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab55a402068039d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_lg')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "40121d825c876053"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Let us add the Party"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6adfbdc9659f10c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = df_full.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b484663e3de6ff0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Chunky chunk chunk\n",
    "# Group by speaker and concatenate all text spoken by the same speaker\n",
    "grouped_df = df1.groupby('Name')['Text_Spoken'].apply(' '.join).reset_index()\n",
    "\n",
    "# Add the 'Party' column to the grouped_df\n",
    "grouped_df = grouped_df.merge(df1[['Name', 'Party']].drop_duplicates(), on='Name')\n",
    "\n",
    "# Function to process text in chunks\n",
    "def process_text_in_chunks(text, chunk_size=1000000):\n",
    "    # Process the text in chunks of the given size\n",
    "    doc = nlp(text[:chunk_size])\n",
    "    processed_text = ' '.join([token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and token.is_alpha])\n",
    "    for i in range(chunk_size, len(text), chunk_size):\n",
    "        doc = nlp(text[i:i+chunk_size])\n",
    "        processed_text += ' ' + ' '.join([token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and token.is_alpha])\n",
    "    return processed_text\n",
    "\n",
    "# Apply preprocessing to the grouped DataFrame\n",
    "grouped_df['Processed_Text'] = grouped_df['Text_Spoken'].apply(lambda text: process_text_in_chunks(text))\n",
    "\n",
    "# Vectorize the text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(grouped_df['Processed_Text'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Convert cosine similarity matrix to DataFrame\n",
    "cosine_sim_df_text = pd.DataFrame(cosine_sim, index=grouped_df['Name'], columns=grouped_df['Name'])\n",
    "\n",
    "# Display the similarity matrix\n",
    "cosine_sim_df_text"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6ec160b48a541a23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the cosine similarity matrix to a CSV file\n",
    "cosine_sim_df_text.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/cosine_similarity_matrix.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a70c0eb6137a3a34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "party_colors_map = {\n",
    "    'SPD': 'red',\n",
    "    'PDS': '#801818',\n",
    "    'CDU': 'white',\n",
    "    'FDP': 'yellow',\n",
    "    'Die Grünen': 'green',\n",
    "    'CSU': 'white',\n",
    "    'AfD': '#0489DB',\n",
    "    'Die Linke': 'pink',\n",
    "    'fraktionslos': 'white',\n",
    "    'LKR': '#FE8100',\n",
    "    'SSW': '#00277E'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "84002c045f87370f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and associate each node with a party\n",
    "for index, row in grouped_df.iterrows():\n",
    "    G.add_node(row['Name'], party=row['Party'])\n",
    "\n",
    "# Get a list of colors for each node\n",
    "node_colors = party_colors_map\n",
    "\n",
    "# Define a threshold for similarity to draw an edge\n",
    "threshold = 0.6  # You may need to adjust this value\n",
    "\n",
    "# Add edges to the graph\n",
    "for i, speaker1 in enumerate(cosine_sim_df_text.index):\n",
    "    for j, speaker2 in enumerate(cosine_sim_df_text.columns):\n",
    "        if i < j:  # This ensures that each pair is only considered once\n",
    "            similarity = cosine_sim_df_text.iloc[i, j]\n",
    "            if similarity > threshold:\n",
    "                G.add_edge(speaker1, speaker2, weight=similarity)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(20, 10), facecolor='#282828')\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "#pos = nx.spring_layout(G, k=0.1)  # k is the optimal distance between nodes, may need to be adjusted\n",
    "\n",
    "# Create a subgraph of G that only includes the largest connected component\n",
    "# If you want to include smaller connected components as well, you can adjust this part\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "subgraph = G.subgraph(largest_cc)\n",
    "\n",
    "# Draw only the nodes and edges from the largest connected component\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color=[party_colors_map[subgraph.nodes[speaker]['party']] for speaker in subgraph.nodes], alpha=0.7, node_size=590)  # Adjust node_size as needed\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='gray', alpha=0.5, width=0.5)\n",
    "\n",
    "\n",
    "# Create a legend for the color map\n",
    "party_labels = list(party_colors_map.keys())\n",
    "patches = [plt.Line2D([0], [0], marker='o', color='w', label=party,\n",
    "                      markersize=10, markerfacecolor=color) for party, color in party_colors_map.items()]\n",
    "plt.legend(handles=patches, title=\"Political Parties\", loc='upper left', bbox_to_anchor=(1, 1), fontsize='large')\n",
    "\n",
    "plt.title('Network Graph of Speaker Similarity',  fontsize=20, loc='center', color='white')\n",
    "plt.axis('off')\n",
    "plt.savefig('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Präsentation/Graphs/speaker_similarity_graph_1.png', dpi=300, bbox_inches='tight', facecolor='#282828')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fd2a41ce505edffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Networkgraph Based on Sentiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f0b9d6e4930009a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/sentiment_analysis_all.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b89153d75e873680"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sentiment['Party'] = df_sentiment['Party'].replace('Bündnis 90/Die Grünen', 'Die Grünen')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "790054de90d3c3bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Group by 'Name' and calculate the mean of each sentiment\n",
    "grouped_sentiment_df = df_sentiment.groupby('Name')[['positive', 'neutral', 'negative']].mean().reset_index()\n",
    "\n",
    "# Add the 'Party' column to the grouped_df before creating the sentiment matrix\n",
    "grouped_sentiment_df = grouped_sentiment_df.merge(df_sentiment[['Name', 'Party']].drop_duplicates(), on='Name')\n",
    "\n",
    "# Create the sentiment matrix from the grouped DataFrame\n",
    "sentiment_matrix = grouped_sentiment_df[['positive', 'neutral', 'negative']].values\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim_sentiment = cosine_similarity(sentiment_matrix, sentiment_matrix)\n",
    "\n",
    "# Convert cosine similarity matrix to DataFrame\n",
    "cosine_sim_df_sentiment = pd.DataFrame(cosine_sim_sentiment, \n",
    "                                       index=grouped_sentiment_df['Name'], \n",
    "                                       columns=grouped_sentiment_df['Name'])\n",
    "\n",
    "# Display the similarity matrix\n",
    "cosine_sim_df_sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bfede61cf6adf7f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the cosine similarity matrix to a CSV file\n",
    "cosine_sim_df_sentiment.to_csv('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Final_DF/cosine_sim_df_sentiment.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "23fd3b40cf57ab94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and associate each node with a party\n",
    "for index, row in grouped_sentiment_df.iterrows():\n",
    "    G.add_node(row['Name'], party=row['Party'])\n",
    "\n",
    "# Get a list of colors for each node\n",
    "node_colors = party_colors_map\n",
    "\n",
    "# Define a threshold for similarity to draw an edge\n",
    "threshold = 0.999  # You may need to adjust this value\n",
    "\n",
    "# Add edges to the graph\n",
    "for i, speaker1 in enumerate(cosine_sim_df_sentiment.index):\n",
    "    for j, speaker2 in enumerate(cosine_sim_df_sentiment.columns):\n",
    "        if i < j:  # This ensures that each pair is only considered once\n",
    "            similarity = cosine_sim_df_sentiment.iloc[i, j]\n",
    "            if similarity > threshold:\n",
    "                G.add_edge(speaker1, speaker2, weight=similarity)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(20, 10), facecolor='#282828')\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "#pos = nx.spring_layout(G, k=0.1)  # k is the optimal distance between nodes, may need to be adjusted\n",
    "\n",
    "# Create a subgraph of G that only includes the largest connected component\n",
    "# If you want to include smaller connected components as well, you can adjust this part\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "subgraph = G.subgraph(largest_cc)\n",
    "\n",
    "# Draw only the nodes and edges from the largest connected component\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color=[party_colors_map[subgraph.nodes[speaker]['party']] for speaker in subgraph.nodes], alpha=0.7, node_size=100)  # Adjust node_size as needed\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='gray', alpha=0.5, width=0.5)\n",
    "\n",
    "\n",
    "# Create a legend for the color map\n",
    "party_labels = list(party_colors_map.keys())\n",
    "patches = [plt.Line2D([0], [0], marker='o', color='w', label=party,\n",
    "                      markersize=10, markerfacecolor=color) for party, color in party_colors_map.items()]\n",
    "plt.legend(handles=patches, title=\"Political Parties\", loc='upper left', bbox_to_anchor=(1, 1), fontsize='large')\n",
    "\n",
    "plt.title('Network Graph of Speaker Similarity',  fontsize=20, loc='center', color='white')\n",
    "plt.axis('off')\n",
    "plt.savefig('/Users/merlesteffen/Documents/Education/WBS_Coding_School/Bootcamp/Sentiment_In_Session/Präsentation/Graphs/4.png', dpi=300, bbox_inches='tight', facecolor='#282828')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "47e991d377776b76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
